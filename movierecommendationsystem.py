# -*- coding: utf-8 -*-
"""movieRecommendationSystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1acGGBxQPVZ13saNiWKr_PYuvKk5ykF-P
"""

import numpy as np
import pandas as pd
import difflib
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from wordcloud import WordCloud
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

df = pd.read_csv("movies.csv")

df.shape

df.head()

df.info()

required_columns = ["genres","keywords","tagline","overview","cast","director","original_title"]
df = df[required_columns]

df.shape

df.info()

df = df.dropna().reset_index(drop = True)

df.info()

df["combined"] = df["genres"]+df["keywords"]+df["tagline"]+df["overview"]+df["cast"]+df["director"]+df["original_title"]

df.head()

data = df[["original_title", "combined"]]

data.head()

#wordcloud for movie content
combined_text = " ".join(df["combined"])
wordcloud = WordCloud(width = 800, height =400, background_color = "white").generate(combined_text)

plt.imshow(wordcloud)
plt.title("most common words in movie content")
plt.show()

nltk.download("punkt")
nltk.download("punkt_tab")
nltk.download("stopwords")

stop_words = set(stopwords.words("english"))

def preprocess_text(text):
  #removing special characters
  text = re.sub(r"[^a-zA-Z\s]","",text)
  #convert to lower case
  text = text.lower()
  #tokenize and remove stopwords
  tokens = word_tokenize(text)
  tokens = [word for word in tokens if word not in stop_words]
  return " ".join(tokens)

data["cleaned_text"] = df["combined"].apply(preprocess_text)

data.head()

#vectorization
tfidf_vectorization = TfidfVectorizer()
tfidf_matrix = tfidf_vectorization.fit_transform(data["cleaned_text"])

print(tfidf_matrix)

#cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix,tfidf_matrix)

print(cosine_sim)

def recommend_movies(movie_name, cosine_sim = cosine_sim, df = data,top_n=5):
  #find the index of movies
  idx = df[df["original_title"].str.lower() == movie_name.lower()].index
  if len(idx) == 0:
    return "movie not found in the database"
  idx = idx[0]

  #get the similarity score
  sim_scores = list(enumerate(cosine_sim[idx]))
  sim_scores = sorted(sim_scores, key=lambda i:i[1], reverse = True)
  #lambda use second value to sort (1,0.5) one being the index and 0,5 similarity
  # so lambda sorts by similarity
  sim_scores = sim_scores[1 : top_n+1]

  #get movie indices
  movie_indices = [i[0] for i in sim_scores]

  # return top n movie recommendstions
  return df[["original_title"]].iloc[movie_indices]

data["original_title"]

row_index = df[df["original_title"].str.lower() == "on the downlow".lower()].index
print(row_index)

movie_name = data["original_title"][62]
print(movie_name)

print("the recommendation for the movies are")
recommendation = recommend_movies(movie_name)
print(recommendation)



